{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4282c9bb573e4c1185666a5341a5009b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2876ffbc274a4e548d998a1591e6b13d",
              "IPY_MODEL_b2996dcf98df4c2e90c692adc044f584",
              "IPY_MODEL_96078f4a60ac449091281670cd94987a"
            ],
            "layout": "IPY_MODEL_f6de9007f1f74221be7963aa503da320"
          }
        },
        "2876ffbc274a4e548d998a1591e6b13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbebab44e92b465f9864aeb4fabb8342",
            "placeholder": "​",
            "style": "IPY_MODEL_b4fbb5a5c49842c5997335d262387736",
            "value": "config.json: 100%"
          }
        },
        "b2996dcf98df4c2e90c692adc044f584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90415cb6694a47289e1f42522bd7dc48",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7975607c2fb4bf38c653b35d2b60bb5",
            "value": 483
          }
        },
        "96078f4a60ac449091281670cd94987a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc5d65a7645d4a0ba7578f6f9a61cec1",
            "placeholder": "​",
            "style": "IPY_MODEL_a5b0279ecd6947d996dc1989f4a30f1f",
            "value": " 483/483 [00:00&lt;00:00, 31.8kB/s]"
          }
        },
        "f6de9007f1f74221be7963aa503da320": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbebab44e92b465f9864aeb4fabb8342": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4fbb5a5c49842c5997335d262387736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90415cb6694a47289e1f42522bd7dc48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7975607c2fb4bf38c653b35d2b60bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc5d65a7645d4a0ba7578f6f9a61cec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5b0279ecd6947d996dc1989f4a30f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f318299c5f6345e996771315d39f5357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3944e391cffd4c8689eba372c528c1cb",
              "IPY_MODEL_5d08250e3a38420bb9aa9afa9759ee22",
              "IPY_MODEL_34bfc01835a1437e9030c7d6befb8a8d"
            ],
            "layout": "IPY_MODEL_bf861d97b9704f2fb93853209fb35ee5"
          }
        },
        "3944e391cffd4c8689eba372c528c1cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2312bedebfc43558e72d1cb5f2a509d",
            "placeholder": "​",
            "style": "IPY_MODEL_600d8be697304a72bd487567e4b5e6b9",
            "value": "model.safetensors: 100%"
          }
        },
        "5d08250e3a38420bb9aa9afa9759ee22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bd5a88e56c1489cb7b053f454dc17b9",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69e22bf247c44029819ef18882025cb2",
            "value": 267954768
          }
        },
        "34bfc01835a1437e9030c7d6befb8a8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7cab605d2e04c2ea7e2c4fb5001dd96",
            "placeholder": "​",
            "style": "IPY_MODEL_df39fb6033a6471e944b98c34aff2ae5",
            "value": " 268M/268M [00:02&lt;00:00, 165MB/s]"
          }
        },
        "bf861d97b9704f2fb93853209fb35ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2312bedebfc43558e72d1cb5f2a509d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "600d8be697304a72bd487567e4b5e6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bd5a88e56c1489cb7b053f454dc17b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69e22bf247c44029819ef18882025cb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7cab605d2e04c2ea7e2c4fb5001dd96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df39fb6033a6471e944b98c34aff2ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5e2fb94e1924857abfc5aa9abbfaeaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9746d031fe03479da9d57ece731933da",
              "IPY_MODEL_ab1f1e0012064222adf6f081bbcd1529",
              "IPY_MODEL_2bf08893164e49d5bca3c0e52081d68c"
            ],
            "layout": "IPY_MODEL_691665fc2c55429494762488d73f555a"
          }
        },
        "9746d031fe03479da9d57ece731933da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58ec871a8b8a4ab8a3b3d3d14253fdcb",
            "placeholder": "​",
            "style": "IPY_MODEL_0b56de0bbb5f410d852227704d67b03f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ab1f1e0012064222adf6f081bbcd1529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39188bd775344dd9b2e2c11b1b4ad85a",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9710ae945a3c4bbf8df2e81e121ebb6c",
            "value": 48
          }
        },
        "2bf08893164e49d5bca3c0e52081d68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70bc3f4cf28241d08c38065f74a78f7f",
            "placeholder": "​",
            "style": "IPY_MODEL_d27400e7683f497a85a6459e73a1a0c0",
            "value": " 48.0/48.0 [00:00&lt;00:00, 3.78kB/s]"
          }
        },
        "691665fc2c55429494762488d73f555a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58ec871a8b8a4ab8a3b3d3d14253fdcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b56de0bbb5f410d852227704d67b03f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39188bd775344dd9b2e2c11b1b4ad85a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9710ae945a3c4bbf8df2e81e121ebb6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70bc3f4cf28241d08c38065f74a78f7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d27400e7683f497a85a6459e73a1a0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37513334cab9441ca76c16548d88ff61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d35b1ed9e414d02b26351fa5d2a30a5",
              "IPY_MODEL_f9a775fefe6d4dc3998539f09bfed0c5",
              "IPY_MODEL_5551e8dbf0dc485bbd28b4431d7e813a"
            ],
            "layout": "IPY_MODEL_730bd6352b544820ba02407de63aedbf"
          }
        },
        "4d35b1ed9e414d02b26351fa5d2a30a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93f89254e8f14fc3b8c73559f523d7c4",
            "placeholder": "​",
            "style": "IPY_MODEL_1a015d41e70b4a05adfb26f0312d0f9d",
            "value": "vocab.txt: 100%"
          }
        },
        "f9a775fefe6d4dc3998539f09bfed0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1549aafd79a4407b99a67905bab2ab8",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf7662f4232e41018d8e81a325ea4793",
            "value": 231508
          }
        },
        "5551e8dbf0dc485bbd28b4431d7e813a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a58bd94865948a4b20b5370c346fcf6",
            "placeholder": "​",
            "style": "IPY_MODEL_637ad2d406e942f492cffd690d65d84b",
            "value": " 232k/232k [00:00&lt;00:00, 4.45MB/s]"
          }
        },
        "730bd6352b544820ba02407de63aedbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93f89254e8f14fc3b8c73559f523d7c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a015d41e70b4a05adfb26f0312d0f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1549aafd79a4407b99a67905bab2ab8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7662f4232e41018d8e81a325ea4793": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a58bd94865948a4b20b5370c346fcf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "637ad2d406e942f492cffd690d65d84b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5658fa480fc84f1ba18048831fdbcde6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c1847af15ac4a4da23744cb0c15481a",
              "IPY_MODEL_508f1765387e4706a97b1feeddb48369",
              "IPY_MODEL_0dbe8dc359e24deb8c5e201fc9fd2dc4"
            ],
            "layout": "IPY_MODEL_f445621235554fb4b018b5a71b8bb4d2"
          }
        },
        "7c1847af15ac4a4da23744cb0c15481a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41470fbbfca246d5a5ca5566cf8a92ee",
            "placeholder": "​",
            "style": "IPY_MODEL_6d949427e53f40d593ecee7aec03e31a",
            "value": "tokenizer.json: 100%"
          }
        },
        "508f1765387e4706a97b1feeddb48369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79d7b2015a4f43a881a10e282e98552b",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e110464661e415dac26d308127f83a3",
            "value": 466062
          }
        },
        "0dbe8dc359e24deb8c5e201fc9fd2dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d31736426c254bb284a3234438b4bde2",
            "placeholder": "​",
            "style": "IPY_MODEL_9e87c63102e241c7abe1174ea0232fac",
            "value": " 466k/466k [00:00&lt;00:00, 23.4MB/s]"
          }
        },
        "f445621235554fb4b018b5a71b8bb4d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41470fbbfca246d5a5ca5566cf8a92ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d949427e53f40d593ecee7aec03e31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79d7b2015a4f43a881a10e282e98552b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e110464661e415dac26d308127f83a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d31736426c254bb284a3234438b4bde2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e87c63102e241c7abe1174ea0232fac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch  wandb tqdm"
      ],
      "metadata": {
        "id": "36qu-ABHagE0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a0b1625-cbe8-4578-829e-9689a9454c6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.26.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgpUPfrE7wY6",
        "outputId": "b7e2aa19-7322-4a77-c7f6-1d61d7fd2184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtMtJtJy6GjQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load saved tensors\n",
        "input_ids = torch.load(\"/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/tokenized_tensors/input_ids.pt\")\n",
        "attention_mask = torch.load(\"/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/tokenized_tensors/attention_mask.pt\")\n",
        "labels = torch.load(\"/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/tokenized_tensors/labels.pt\")\n"
      ],
      "metadata": {
        "id": "wy1LFx5j6TfE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "d8af797b-1a15-4f31-e079-91617ae68811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ed8cf1433041>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load saved tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/tokenized_tensors/input_ids.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/tokenized_tensors/attention_mask.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/tokenized_tensors/labels.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    752\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Weights & Biases\n",
        "\n",
        "#0228da7fe575258568d48818e3f64c2e74895a16\n",
        "\n",
        "wandb.init(project=\"distilbert_cnn_v3\", name=\"1epoch\", resume=\"allow\")"
      ],
      "metadata": {
        "id": "4BNrI7-i6Z5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#number 1\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# ✅ Step 6: Define Custom Dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_mask, labels):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.input_ids[idx],\n",
        "            'attention_mask': self.attention_mask[idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n"
      ],
      "metadata": {
        "id": "j5fsAPmiUzA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#number 2\n",
        "\n",
        "# Assuming you've saved the tokenized tensors as .pt files\n",
        "input_ids = torch.load('/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/tokenized_tensors/input_ids.pt')\n",
        "attention_mask = torch.load('/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/tokenized_tensors/attention_mask.pt')\n",
        "labels = torch.load('/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/tokenized_tensors/labels.pt')\n",
        "\n",
        "# ✅ Recreate the dataset with loaded tensors\n",
        "dataset = CustomDataset(input_ids, attention_mask, labels)\n"
      ],
      "metadata": {
        "id": "uiwTcLAIe1Rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Number 3\n",
        "\n",
        "#when resuming the training\n",
        "#run this before creating dataset\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "# Load the saved split indices\n",
        "train_indices, val_indices = torch.load('/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/tokenized_tensors/split_indices.pt')\n",
        "\n",
        "# Use Subset to create datasets with the saved indices\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "val_dataset = Subset(dataset, val_indices)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 64  # or whatever you prefer\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "LoQEZcSHe1vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/Text Model in Action/model checkpoints/2025-03-28_13-05-49/checkpoint-231840\""
      ],
      "metadata": {
        "id": "DayuXXvpfODk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DistilBERT_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bert = DistilBertModel.from_pretrained(config.model_checkpoint)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(768, 128, kernel_size=k) for k in [2, 3, 4]  # Bi/tri/4-gram filters\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.classifier = nn.Linear(128 * 3, 1)  # 3 filter groups\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = outputs.last_hidden_state.permute(0, 2, 1)  # (batch, 768, seq_len)\n",
        "\n",
        "        conv_features = [torch.relu(conv(hidden_state)) for conv in self.convs]\n",
        "        pooled = [torch.max(f, dim=2)[0] for f in conv_features]  # Global max pooling\n",
        "        concat = self.dropout(torch.cat(pooled, dim=1))\n",
        "        return self.classifier(concat)"
      ],
      "metadata": {
        "id": "WiWWoaTwfsT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Model & Optimizer\n",
        "model = DistilBERT_CNN().to(config.device)\n",
        "optimizer = torch.optim.AdamW([\n",
        "    {'params': model.bert.parameters(), 'lr': config.bert_lr},\n",
        "    {'params': model.convs.parameters(), 'lr': config.cnn_lr},\n",
        "    {'params': model.classifier.parameters(), 'lr': config.cnn_lr}\n",
        "])\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([config.pos_weight]).to(config.device))\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ],
      "metadata": {
        "id": "5CW3Wo1WfvWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0228da7fe575258568d48818e3f64c2e74895a16\n",
        "!wandb login --relogin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yDn6Y7lqOsc",
        "outputId": "60ac188b-8489-41d7-b5c3-f4821ff774d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "# Initialize W&B with project name, config, and tags\n",
        "wandb.init(\n",
        "    project=\"distilbert_cnn_v2\",  # Your project name\n",
        "    config={                       # Hyperparameters/dataset info\n",
        "        \"model\": \"DistilBERT + CNN\",\n",
        "        \"batch_size\": 64,\n",
        "        \"epochs\": 10,\n",
        "        \"class_ratio\": \"60:40\",\n",
        "        \"pos_weight\": 1.5,\n",
        "        \"learning_rate_bert\": 2e-5,\n",
        "        \"learning_rate_cnn\": 1e-4\n",
        "    },\n",
        "    tags=[\"baseline\", \"hybrid\"],  # Organize runs\n",
        "    notes=\"Initial run with DistilBERT+CNN for suicide detection\"  # Add context\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "QKuvhCAlpttF",
        "outputId": "61e64bdc-e8ec-469b-8d9a-a5f46cab1def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmuhib-57838\u001b[0m (\u001b[33mmuhib-57838-iqra-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250411_210436-6nb1s9r7</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2/runs/6nb1s9r7' target=\"_blank\">dazzling-haze-2</a></strong> to <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2/runs/6nb1s9r7' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2/runs/6nb1s9r7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2/runs/6nb1s9r7?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7ef28899e510>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "id": "-yVN6eF9qNSc",
        "outputId": "b07add7c-987a-46b7-a452-b4cb15dfad2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'test_training' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-151bf7703c9c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install wandb transformers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_training' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing the wandb.\n",
        "import torch\n",
        "import wandb\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Initialize W&B (test project)\n",
        "wandb.init(project=\"distilbert_cnn_v2\", name=\"dry-run\", save_code=True)\n",
        "\n",
        "# Synthetic data generator\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, num_samples=100):\n",
        "        self.texts = [\"This is a test sentence.\"] * num_samples  # Dummy text\n",
        "        self.labels = np.random.randint(0, 2, num_samples)  # Random 0/1 labels\n",
        "\n",
        "        # Tokenize with DistilBERT\n",
        "        self.tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.encodings = self.tokenizer(\n",
        "            self.texts, truncation=True, padding=True, max_length=128\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            \"input_ids\": torch.tensor(self.encodings[\"input_ids\"][idx]),\n",
        "            \"attention_mask\": torch.tensor(self.encodings[\"attention_mask\"][idx]),\n",
        "            \"labels\": torch.tensor(self.labels[idx]),\n",
        "        }\n",
        "\n",
        "# Minimal model (for testing)\n",
        "class TestModel(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.classifier = torch.nn.Linear(768, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        return self.classifier(outputs.last_hidden_state[:, 0, :])\n",
        "\n",
        "# Training loop with logging\n",
        "def test_training():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = TestModel().to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "    criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Synthetic data\n",
        "    dataset = TestDataset(num_samples=16)  # Tiny batch\n",
        "    loader = DataLoader(dataset, batch_size=4)\n",
        "\n",
        "    for epoch in range(2):  # 2 epochs for testing\n",
        "        model.train()\n",
        "        all_preds, all_labels = [], []\n",
        "\n",
        "        for batch in loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].float().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(input_ids, attention_mask).squeeze()\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Simulate predictions\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy()\n",
        "            all_preds.extend(preds)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = (np.array(all_preds) == np.array(all_labels)).mean()\n",
        "        precision = precision_score(all_labels, all_preds, zero_division=0)\n",
        "        recall = recall_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "        # Log to W&B\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch,\n",
        "            \"loss\": loss.item(),\n",
        "            \"accuracy\": accuracy,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "                y_true=all_labels,\n",
        "                preds=all_preds,\n",
        "                class_names=[\"non_suicidal\", \"suicidal\"]\n",
        "            )\n",
        "        })\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "# Run the test\n",
        "test_training()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925,
          "referenced_widgets": [
            "4282c9bb573e4c1185666a5341a5009b",
            "2876ffbc274a4e548d998a1591e6b13d",
            "b2996dcf98df4c2e90c692adc044f584",
            "96078f4a60ac449091281670cd94987a",
            "f6de9007f1f74221be7963aa503da320",
            "bbebab44e92b465f9864aeb4fabb8342",
            "b4fbb5a5c49842c5997335d262387736",
            "90415cb6694a47289e1f42522bd7dc48",
            "f7975607c2fb4bf38c653b35d2b60bb5",
            "fc5d65a7645d4a0ba7578f6f9a61cec1",
            "a5b0279ecd6947d996dc1989f4a30f1f",
            "f318299c5f6345e996771315d39f5357",
            "3944e391cffd4c8689eba372c528c1cb",
            "5d08250e3a38420bb9aa9afa9759ee22",
            "34bfc01835a1437e9030c7d6befb8a8d",
            "bf861d97b9704f2fb93853209fb35ee5",
            "f2312bedebfc43558e72d1cb5f2a509d",
            "600d8be697304a72bd487567e4b5e6b9",
            "2bd5a88e56c1489cb7b053f454dc17b9",
            "69e22bf247c44029819ef18882025cb2",
            "e7cab605d2e04c2ea7e2c4fb5001dd96",
            "df39fb6033a6471e944b98c34aff2ae5",
            "b5e2fb94e1924857abfc5aa9abbfaeaf",
            "9746d031fe03479da9d57ece731933da",
            "ab1f1e0012064222adf6f081bbcd1529",
            "2bf08893164e49d5bca3c0e52081d68c",
            "691665fc2c55429494762488d73f555a",
            "58ec871a8b8a4ab8a3b3d3d14253fdcb",
            "0b56de0bbb5f410d852227704d67b03f",
            "39188bd775344dd9b2e2c11b1b4ad85a",
            "9710ae945a3c4bbf8df2e81e121ebb6c",
            "70bc3f4cf28241d08c38065f74a78f7f",
            "d27400e7683f497a85a6459e73a1a0c0",
            "37513334cab9441ca76c16548d88ff61",
            "4d35b1ed9e414d02b26351fa5d2a30a5",
            "f9a775fefe6d4dc3998539f09bfed0c5",
            "5551e8dbf0dc485bbd28b4431d7e813a",
            "730bd6352b544820ba02407de63aedbf",
            "93f89254e8f14fc3b8c73559f523d7c4",
            "1a015d41e70b4a05adfb26f0312d0f9d",
            "e1549aafd79a4407b99a67905bab2ab8",
            "bf7662f4232e41018d8e81a325ea4793",
            "3a58bd94865948a4b20b5370c346fcf6",
            "637ad2d406e942f492cffd690d65d84b",
            "5658fa480fc84f1ba18048831fdbcde6",
            "7c1847af15ac4a4da23744cb0c15481a",
            "508f1765387e4706a97b1feeddb48369",
            "0dbe8dc359e24deb8c5e201fc9fd2dc4",
            "f445621235554fb4b018b5a71b8bb4d2",
            "41470fbbfca246d5a5ca5566cf8a92ee",
            "6d949427e53f40d593ecee7aec03e31a",
            "79d7b2015a4f43a881a10e282e98552b",
            "1e110464661e415dac26d308127f83a3",
            "d31736426c254bb284a3234438b4bde2",
            "9e87c63102e241c7abe1174ea0232fac"
          ]
        },
        "id": "xNHR0kXzrxOE",
        "outputId": "f4c5a8b7-4c84-4edd-ffd7-46ee4c9b2763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmuhib-57838\u001b[0m (\u001b[33mmuhib-57838-iqra-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250411_211117-bauh2brq</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2/runs/bauh2brq' target=\"_blank\">dry-run</a></strong> to <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2/runs/bauh2brq' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2/runs/bauh2brq</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4282c9bb573e4c1185666a5341a5009b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f318299c5f6345e996771315d39f5357"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5e2fb94e1924857abfc5aa9abbfaeaf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37513334cab9441ca76c16548d88ff61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5658fa480fc84f1ba18048831fdbcde6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁█</td></tr><tr><td>epoch</td><td>▁█</td></tr><tr><td>loss</td><td>▁█</td></tr><tr><td>precision</td><td>█▁</td></tr><tr><td>recall</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.625</td></tr><tr><td>epoch</td><td>1</td></tr><tr><td>loss</td><td>0.72404</td></tr><tr><td>precision</td><td>0</td></tr><tr><td>recall</td><td>0</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dry-run</strong> at: <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2/runs/bauh2brq' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2/runs/bauh2brq</a><br> View project at: <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v2</a><br>Synced 5 W&B file(s), 2 media file(s), 6 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250411_211117-bauh2brq/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7YQsTjDInfRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install Dependencies\n",
        "!pip install transformers torch wandb tqdm\n",
        "# !wandb login\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWLBQDa-iIF_",
        "outputId": "aa0a4ed6-ac77-46ea-f660-3b9cbf0c0cf7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Imports & Configuration\n",
        "import torch\n",
        "import wandb\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "class Config:\n",
        "    # Model\n",
        "    model_checkpoint = \"/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/Text Model in Action/model checkpoints/2025-03-28_13-05-49/checkpoint-231840\"\n",
        "    pos_weight = 1.5  # 60:40 class ratio (60/40=1.5)\n",
        "\n",
        "    # Training\n",
        "    batch_size = 32\n",
        "    max_seq_len = 256\n",
        "    bert_lr = 2e-5\n",
        "    cnn_lr = 1e-4\n",
        "    epochs = 24\n",
        "    max_grad_norm = 1.0\n",
        "    dropout = 0.2\n",
        "\n",
        "    checkpoint_dir = \"/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/trained_model_v3\"\n",
        "    resume_epoch = 20  # 👈 Specify which epoch to resume from\n",
        "\n",
        "    # System\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    save_dir = \"/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/trained_model_v3/\"\n",
        "\n",
        "config = Config()\n",
        "\n"
      ],
      "metadata": {
        "id": "_ytHT6Uir17E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Model Architecture\n",
        "class DistilBERT_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bert = DistilBertModel.from_pretrained(config.model_checkpoint)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv1d(768, 128, kernel_size=k) for k in [2, 3, 4]\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.classifier = nn.Linear(128 * 3, 1)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = outputs.last_hidden_state.permute(0, 2, 1)\n",
        "\n",
        "        conv_features = [torch.relu(conv(hidden_state)) for conv in self.convs]\n",
        "        pooled = [torch.max(f, dim=2)[0] for f in conv_features]\n",
        "        concat = self.dropout(torch.cat(pooled, dim=1))\n",
        "        return self.classifier(concat)\n",
        "\n"
      ],
      "metadata": {
        "id": "nUT1_jtquipM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize W&B (test project)\n",
        "wandb.init(project=\"distilbert_cnn_v3\", name=\"2-epochs\", save_code=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "8aMQLaq2v0d_",
        "outputId": "4c23f009-c684-4996-f107-aaaa09be503b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">1-8epoch</strong> at: <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/tpdjq9xr' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/tpdjq9xr</a><br> View project at: <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250415_114202-tpdjq9xr/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250415_114318-kefl2ib2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/kefl2ib2' target=\"_blank\">2-epochs</a></strong> to <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/kefl2ib2' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/kefl2ib2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/kefl2ib2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7a261eaa2390>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create Dataset Class for Pre-Tokenized Data\n",
        "class PreTokenizedDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, input_ids, attention_mask, labels):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_mask = attention_mask\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.input_ids[idx],\n",
        "            'attention_mask': self.attention_mask[idx],\n",
        "            'labels': self.labels[idx]\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# Step 2: Load Your Saved Tensors\n",
        "input_ids = torch.load('/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/tokenized_tensors/input_ids.pt')\n",
        "attention_mask = torch.load('/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/tokenized_tensors/attention_mask.pt')\n",
        "labels = torch.load('/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/tokenized_tensors/labels.pt')\n",
        "\n",
        "# Step 3: Create Full Dataset\n",
        "full_dataset = PreTokenizedDataset(input_ids, attention_mask, labels)\n",
        "\n",
        "# Step 4: Load Split Indices\n",
        "train_indices, val_indices = torch.load('/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/tokenized_tensors/split_indices.pt')\n",
        "\n",
        "# Step 5: Create Train/Validation Subsets\n",
        "train_dataset = Subset(full_dataset, train_indices)\n",
        "val_dataset = Subset(full_dataset, val_indices)\n",
        "\n",
        "# Step 6: Create DataLoaders\n",
        "batch_size = 32  # Match your config\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    pin_memory=True  # Faster data transfer to GPU\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# Step 7: Verify Data Shapes\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(\"Sample batch:\")\n",
        "print(f\"Input IDs shape: {sample_batch['input_ids'].shape}\")\n",
        "print(f\"Attention mask shape: {sample_batch['attention_mask'].shape}\")\n",
        "print(f\"Labels shape: {sample_batch['labels'].shape}\")\n",
        "\n",
        "# Expected output (for batch_size=32 and max_seq_len=128):\n",
        "# Input IDs shape: torch.Size([32, 128])\n",
        "# Attention mask shape: torch.Size([32, 128])\n",
        "# Labels shape: torch.Size([32])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H8X4rSkq0v3",
        "outputId": "9a35c365-02dc-4e12-e3ed-24f2a1a49731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample batch:\n",
            "Input IDs shape: torch.Size([32, 512])\n",
            "Attention mask shape: torch.Size([32, 512])\n",
            "Labels shape: torch.Size([32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Training Loop with FP16\n",
        "def train_model(train_loader, val_loader):\n",
        "    # Initialize\n",
        "    model = DistilBERT_CNN().to(config.device)\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {'params': model.bert.parameters(), 'lr': config.bert_lr},\n",
        "        {'params': model.convs.parameters(), 'lr': config.cnn_lr},\n",
        "        {'params': model.classifier.parameters(), 'lr': config.cnn_lr}\n",
        "    ])\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([config.pos_weight]).to(config.device))\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    best_val_f1 = 0.0\n",
        "\n",
        "    # W&B Init\n",
        "    wandb.init(project=\"distilbert_cn_v3\", name = \"2-4epochs\" , config=vars(config),\n",
        "              tags=[\"distilbert-cnn\", \"fp16\"])\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        train_preds, train_true = [], []\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.epochs} [Train]\"):\n",
        "            input_ids = batch['input_ids'].to(config.device)\n",
        "            attention_mask = batch['attention_mask'].to(config.device)\n",
        "            labels = batch['labels'].float().to(config.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Mixed precision forward\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(input_ids, attention_mask).squeeze()\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward with gradient scaling\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            # Track metrics\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).cpu().float()\n",
        "            train_preds.extend(preds.numpy())\n",
        "            train_true.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_preds, val_true = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config.epochs} [Val]\"):\n",
        "                input_ids = batch['input_ids'].to(config.device)\n",
        "                attention_mask = batch['attention_mask'].to(config.device)\n",
        "                labels = batch['labels'].float().to(config.device)\n",
        "\n",
        "                outputs = model(input_ids, attention_mask).squeeze()\n",
        "                preds = (torch.sigmoid(outputs) > 0.5).cpu().float()\n",
        "                val_preds.extend(preds.numpy())\n",
        "                val_true.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Calculate Metrics\n",
        "        def calculate_metrics(true, preds, prefix):\n",
        "            return {\n",
        "                f\"{prefix}/loss\": loss.item() if 'loss' in locals() else 0,\n",
        "                f\"{prefix}/accuracy\": (np.array(true) == np.array(preds)).mean(),\n",
        "                f\"{prefix}/precision\": precision_score(true, preds, average='binary', zero_division=0),\n",
        "                f\"{prefix}/recall\": recall_score(true, preds, average='binary', zero_division=0),\n",
        "                f\"{prefix}/f1\": f1_score(true, preds, average='binary', zero_division=0),\n",
        "                f\"{prefix}/cm\": wandb.plot.confusion_matrix(\n",
        "                    y_true=true,\n",
        "                    preds=preds,\n",
        "                    class_names=[\"non-suicidal\", \"suicidal\"]\n",
        "                )\n",
        "            }\n",
        "\n",
        "        # Log to W&B\n",
        "        metrics = {\n",
        "            \"epoch\": epoch + 1,\n",
        "            **calculate_metrics(train_true, train_preds, \"train\"),\n",
        "            **calculate_metrics(val_true, val_preds, \"val\")\n",
        "        }\n",
        "        wandb.log(metrics)\n",
        "\n",
        "        # Save Best Model\n",
        "        if metrics[\"val/f1\"] > best_val_f1:\n",
        "            best_val_f1 = metrics[\"val/f1\"]\n",
        "            torch.save(model.state_dict(), f\"{config.save_dir}/best_model.pt\")\n",
        "            wandb.save(f\"{config.save_dir}/best_model.pt\")\n",
        "\n",
        "    wandb.finish()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZR6LhokBud38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the testing epoch 1 with\n",
        "#failed to create an instance. double baam. issey naya object/instance bn jaiga.\n",
        "checkpoint_path = \"/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/trained_model_v3/checkpoint_testing/\"\n",
        "model = DistilBERT_CNN().to(config.device)\n",
        "optimizer = torch.optim.AdamW([\n",
        "        {'params': model.bert.parameters(), 'lr': config.bert_lr},\n",
        "        {'params': model.convs.parameters(), 'lr': config.cnn_lr},\n",
        "        {'params': model.classifier.parameters(), 'lr': config.cnn_lr}\n",
        "    ])\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "checkpoint = {\n",
        "        'epoch': 1,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scaler_state_dict': scaler.state_dict(),\n",
        "        'best_f1': 0.9686  # Track but not used for saving\n",
        "    }\n",
        "torch.save(checkpoint, checkpoint_path)\n",
        "print(f\"💾 Saved checkpoint at epoch {1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "72zD4AHtCySX",
        "outputId": "6ed223be-90b9-4a8f-81b4-dea62fbee8a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'optimizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5b312535b195>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;34m'scaler_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m'best_f1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.9686\u001b[0m  \u001b[0;31m# Track but not used for saving\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = {\n",
        "    'epoch': 1,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'scaler_state_dict': scaler.state_dict(),\n",
        "    'best_f1': best_f1\n",
        "}\n",
        "torch.save(checkpoint, checkpoint_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "8tJL_2xSGNDn",
        "outputId": "d2ba58d1-0460-4165-e4ce-92791d5563e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'optimizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-cee866841530>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m'optimizer_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m'scaler_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m'best_f1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbest_f1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Checkpoint Management Functions\n",
        "\n",
        "def save_checkpoint(epoch, model, optimizer, scaler, config):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch + 1,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scaler_state_dict': scaler.state_dict(),\n",
        "        'best_f1': 0.9686  # Track but not used for saving\n",
        "      }\n",
        "    torch.save(checkpoint, checkpoint_path)\n",
        "    print(f\"💾 Saved checkpoint at epoch {epoch+1}\")\n"
      ],
      "metadata": {
        "id": "In2ajevg_9jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Checkpoint Management Functions\n",
        "def save_checkpoint(epoch, model, optimizer, scaler, config):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch + 1,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scaler_state_dict': scaler.state_dict(),\n",
        "        'best_f1': best_val_f1  # Track but not used for saving\n",
        "    }\n",
        "    torch.save(checkpoint, config.checkpoint_path)\n",
        "    print(f\"💾 Saved checkpoint at epoch {epoch+1}\")\n",
        "\n",
        "def load_checkpoint(config, model, optimizer, scaler):\n",
        "    if os.path.exists(config.checkpoint_path):\n",
        "        checkpoint = torch.load(config.checkpoint_path)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        best_f1 = checkpoint['best_f1']\n",
        "        print(f\"🚀 Resuming from epoch {start_epoch} | Best F1: {best_f1:.4f}\")\n",
        "        return start_epoch, best_f1\n",
        "    return 0, 0.0\n",
        "\n",
        "# Cell 6: Enhanced Training Loop with Resume Support\n",
        "def train_model(train_loader, val_loader):\n",
        "    # Initialize model and optimizer\n",
        "    model = DistilBERT_CNN().to(config.device)\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {'params': model.bert.parameters(), 'lr': config.bert_lr},\n",
        "        {'params': model.convs.parameters(), 'lr': config.cnn_lr},\n",
        "        {'params': model.classifier.parameters(), 'lr': config.cnn_lr}\n",
        "    ])\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([config.pos_weight]).to(config.device))\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    # Load checkpoint if exists\n",
        "    start_epoch, best_val_f1 = load_checkpoint(config, model, optimizer, scaler)\n",
        "\n",
        "    # W&B Initialization\n",
        "    wandb.init(project=\"suicide-detection\",\n",
        "              config=vars(config),\n",
        "              resume=\"allow\",\n",
        "              id=\"suicide-detection-run-1\")  # Fixed run ID for resuming\n",
        "\n",
        "    for epoch in range(start_epoch, config.epochs):\n",
        "        # --- Training Phase ---\n",
        "        model.train()\n",
        "        train_preds, train_true = [], []\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.epochs} [Train]\"):\n",
        "            # ... [existing training code] ...\n",
        "\n",
        "        # --- Validation Phase ---\n",
        "        model.eval()\n",
        "        val_preds, val_true = [], []\n",
        "        with torch.no_grad():\n",
        "            # ... [existing validation code] ...\n",
        "\n",
        "        # --- Metrics Calculation ---\n",
        "        def calculate_metrics(true, preds, prefix):\n",
        "            return {\n",
        "                f\"{prefix}/loss\": criterion(torch.tensor(preds), torch.tensor(true)).item(),\n",
        "                f\"{prefix}/accuracy\": (np.array(true) == np.array(preds)).mean(),\n",
        "                f\"{prefix}/precision\": precision_score(true, preds, zero_division=0),\n",
        "                f\"{prefix}/recall\": recall_score(true, preds, zero_division=0),\n",
        "                f\"{prefix}/f1\": f1_score(true, preds, zero_division=0),\n",
        "                f\"{prefix}/cm\": wandb.plot.confusion_matrix(\n",
        "                    y_true=true,\n",
        "                    preds=preds,\n",
        "                    class_names=[\"non-suicidal\", \"suicidal\"]\n",
        "                )\n",
        "            }\n",
        "\n",
        "        # --- Logging & Checkpointing ---\n",
        "        metrics = {\n",
        "            \"epoch\": epoch + 1,\n",
        "            **calculate_metrics(train_true, train_preds, \"train\"),\n",
        "            **calculate_metrics(val_true, val_preds, \"val\")\n",
        "        }\n",
        "        wandb.log(metrics)\n",
        "\n",
        "        # Save checkpoint every epoch\n",
        "        save_checkpoint(epoch, model, optimizer, scaler, config)\n",
        "\n",
        "    wandb.finish()\n",
        "\n",
        "# Cell 7: Execute Training\n",
        "if __name__ == \"__main__\":\n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Create directories if needed\n",
        "    os.makedirs(config.save_dir, exist_ok=True)\n",
        "\n",
        "    # Start/resume training\n",
        "    train_model(train_loader, val_loader)"
      ],
      "metadata": {
        "id": "mtOCqd_3-HxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Execute Training\n",
        "if __name__ == \"__main__\":\n",
        "    # # Mount Google Drive\n",
        "    # from google.colab import drive\n",
        "    # drive.mount('/content/drive')\n",
        "\n",
        "    # Load your data here\n",
        "    # train_texts, train_labels = ...\n",
        "    # val_texts, val_labels = ...\n",
        "\n",
        "    # # Create datasets\n",
        "    # full_dataset = SuicideDataset(train_texts + val_texts, train_labels + val_labels)\n",
        "    # train_dataset = Subset(full_dataset, train_indices)\n",
        "    # val_dataset = Subset(full_dataset, val_indices)\n",
        "\n",
        "    # # Create loaders\n",
        "    # train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n",
        "    # val_loader = DataLoader(val_dataset, batch_size=config.batch_size)\n",
        "\n",
        "    # Start training\n",
        "    train_model(train_loader, val_loader)"
      ],
      "metadata": {
        "id": "9sByU3y1uX_E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40e44fcd-bdfb-44db-d3bd-56393fe82ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-8dbaa8b6bbd9>:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">1_epoch</strong> at: <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/zi97rec9' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/zi97rec9</a><br> View project at: <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3</a><br>Synced 5 W&B file(s), 0 media file(s), 9 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250414_192844-zi97rec9/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250414_193037-hp4id2no</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/muhib-57838-iqra-university/suicide-detection/runs/hp4id2no' target=\"_blank\">lyric-galaxy-1</a></strong> to <a href='https://wandb.ai/muhib-57838-iqra-university/suicide-detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/muhib-57838-iqra-university/suicide-detection' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/suicide-detection</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/muhib-57838-iqra-university/suicide-detection/runs/hp4id2no' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/suicide-detection/runs/hp4id2no</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/1 [Train]:   0%|          | 0/5127 [00:00<?, ?it/s]<ipython-input-10-8dbaa8b6bbd9>:31: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 1/1 [Train]: 100%|██████████| 5127/5127 [32:47<00:00,  2.61it/s]\n",
            "Epoch 1/1 [Val]: 100%|██████████| 570/570 [04:42<00:00,  2.02it/s]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Saving files without folders. If you want to preserve subdirectories pass base_path to wandb.save, i.e. wandb.save(\"/mnt/folder/file.h5\", base_path=\"/mnt\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>train/accuracy</td><td>▁</td></tr><tr><td>train/f1</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr><tr><td>train/precision</td><td>▁</td></tr><tr><td>train/recall</td><td>▁</td></tr><tr><td>val/accuracy</td><td>▁</td></tr><tr><td>val/f1</td><td>▁</td></tr><tr><td>val/loss</td><td>▁</td></tr><tr><td>val/precision</td><td>▁</td></tr><tr><td>val/recall</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train/accuracy</td><td>0.96855</td></tr><tr><td>train/f1</td><td>0.96081</td></tr><tr><td>train/loss</td><td>0.00419</td></tr><tr><td>train/precision</td><td>0.95765</td></tr><tr><td>train/recall</td><td>0.96399</td></tr><tr><td>val/accuracy</td><td>0.97498</td></tr><tr><td>val/f1</td><td>0.9686</td></tr><tr><td>val/loss</td><td>0.00419</td></tr><tr><td>val/precision</td><td>0.97356</td></tr><tr><td>val/recall</td><td>0.96368</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lyric-galaxy-1</strong> at: <a href='https://wandb.ai/muhib-57838-iqra-university/suicide-detection/runs/hp4id2no' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/suicide-detection/runs/hp4id2no</a><br> View project at: <a href='https://wandb.ai/muhib-57838-iqra-university/suicide-detection' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/suicide-detection</a><br>Synced 5 W&B file(s), 2 media file(s), 4 artifact file(s) and 1 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250414_193037-hp4id2no/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#0228da7fe575258568d48818e3f64c2e74895a16"
      ],
      "metadata": {
        "id": "vOs0Vg6-a62T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "        project=\"distilbert_cnn_v3\",\n",
        "        name=\"epoch_20-24_new\",  # Short unique identifier\n",
        "        config=vars(config),\n",
        "        tags=[\"distilbert-cnn\", \"fp16\", \"production\"],\n",
        "        group=\"hybrid-model-v1\",  # Group related experiments\n",
        "        resume=\"allow\"  # Critical for continuous logging\n",
        "    )"
      ],
      "metadata": {
        "id": "OG7xmCopxq5E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "23effa58-b5a2-412b-d0b2-148637046ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">epoch_20-24</strong> at: <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/uut9da6u' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/uut9da6u</a><br> View project at: <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250419_112843-uut9da6u/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250419_112953-o6lkyvij</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/o6lkyvij' target=\"_blank\">epoch_20-24_new</a></strong> to <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/o6lkyvij' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/o6lkyvij</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/o6lkyvij?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7d47edb4ecd0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "        project=\"distilbert_cnn_v3\",\n",
        "        name=\"epoch_18-20\",  # Short unique identifier\n",
        "        config=vars(config),\n",
        "        tags=[\"distilbert-cnn\", \"fp16\", \"production\"],\n",
        "        group=\"hybrid-model-v1\",  # Group related experiments\n",
        "        resume=\"allow\"  # Critical for continuous logging\n",
        ")\n"
      ],
      "metadata": {
        "id": "FiO_PPd1ogdn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "631b7f85-994c-4c41-ad36-a733ce37bd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250418_190830-wag60adm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/wag60adm' target=\"_blank\">epoch_18-20</a></strong> to <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/wag60adm' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/wag60adm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/wag60adm?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7b7db6448090>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def train_model(train_loader, val_loader, resume=False):\n",
        "    # Model init\n",
        "    model = DistilBERT_CNN().to(config.device)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.AdamW([\n",
        "        {'params': model.bert.parameters(), 'lr': config.bert_lr},\n",
        "        {'params': model.convs.parameters(), 'lr': config.cnn_lr},\n",
        "        {'params': model.classifier.parameters(), 'lr': config.cnn_lr}\n",
        "    ])\n",
        "\n",
        "    # # W&B Configuration\n",
        "    # run_id = None\n",
        "    # if resume and os.path.exists(config.checkpoint_path):\n",
        "    #     checkpoint = torch.load(config.checkpoint_path, map_location=config.device)\n",
        "    #     run_id = checkpoint.get('wandb_run_id', wandb.util.generate_id())\n",
        "    # else:\n",
        "    #     run_id = wandb.util.generate_id()\n",
        "\n",
        "    # Loss & AMP\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([config.pos_weight]).to(config.device))\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    # Tracking\n",
        "    # best_val_f1 = 0.0\n",
        "    start_epoch = 20\n",
        "\n",
        "    # Checkpoint path\n",
        "    checkpoint_dir = config.save_dir\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # 💾 Resume checkpoint if available\n",
        "    if resume:\n",
        "        # Manually construct the target checkpoint filename\n",
        "        target_checkpoint = f\"checkpoint_epoch_{config.resume_epoch}.pt\"\n",
        "        checkpoint_path = os.path.join(config.checkpoint_dir, target_checkpoint)\n",
        "\n",
        "        if not os.path.exists(checkpoint_path):\n",
        "            raise FileNotFoundError(f\"❌ Checkpoint for epoch {config.resume_epoch} not found!\")\n",
        "\n",
        "        checkpoint = torch.load(checkpoint_path, map_location=config.device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        scaler.load_state_dict(checkpoint['scaler_state_dict'])\n",
        "        start_epoch = checkpoint['epoch']  # Will be 12 if resuming epoch 12\n",
        "        best_val_f1 = checkpoint['best_f1']\n",
        "        print(f\"✅ Manually resumed from epoch {start_epoch} (loaded {target_checkpoint})\")\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        best_val_f1 = 0.0\n",
        "\n",
        "        if not os.path.exists(checkpoint_path):\n",
        "            raise FileNotFoundError(f\"❌ Checkpoint for epoch {config.resume_epoch} not found!\")\n",
        "\n",
        "    for epoch in range(start_epoch, config.epochs):\n",
        "        model.train()\n",
        "        train_preds, train_true = [], []\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{config.epochs} [Train]\"):\n",
        "            input_ids = batch['input_ids'].to(config.device)\n",
        "            attention_mask = batch['attention_mask'].to(config.device)\n",
        "            labels = batch['labels'].float().to(config.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(input_ids, attention_mask).squeeze()\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), config.max_grad_norm)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).cpu().float()\n",
        "            train_preds.extend(preds.numpy())\n",
        "            train_true.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_preds, val_true = [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{config.epochs} [Val]\"):\n",
        "                input_ids = batch['input_ids'].to(config.device)\n",
        "                attention_mask = batch['attention_mask'].to(config.device)\n",
        "                labels = batch['labels'].float().to(config.device)\n",
        "\n",
        "                outputs = model(input_ids, attention_mask).squeeze()\n",
        "                preds = (torch.sigmoid(outputs) > 0.5).cpu().float()\n",
        "                val_preds.extend(preds.numpy())\n",
        "                val_true.extend(labels.cpu().numpy())\n",
        "\n",
        "        # Metrics\n",
        "        def calculate_metrics(true, preds, prefix):\n",
        "            return {\n",
        "                f\"{prefix}/loss\": loss.item(),\n",
        "                f\"{prefix}/accuracy\": (np.array(true) == np.array(preds)).mean(),\n",
        "                f\"{prefix}/precision\": precision_score(true, preds, average='binary', zero_division=0),\n",
        "                f\"{prefix}/recall\": recall_score(true, preds, average='binary', zero_division=0),\n",
        "                f\"{prefix}/f1\": f1_score(true, preds, average='binary', zero_division=0),\n",
        "                f\"{prefix}/cm\": wandb.plot.confusion_matrix(\n",
        "                    y_true=true,\n",
        "                    preds=preds,\n",
        "                    class_names=[\"non-suicidal\", \"suicidal\"]\n",
        "                )\n",
        "            }\n",
        "\n",
        "        metrics = {\n",
        "            \"epoch\": epoch + 1,\n",
        "            **calculate_metrics(train_true, train_preds, \"train\"),\n",
        "            **calculate_metrics(val_true, val_preds, \"val\")\n",
        "        }\n",
        "        wandb.log(metrics)\n",
        "\n",
        "        # # Save best model (optional)\n",
        "        # if metrics[\"val/f1\"] > best_val_f1:\n",
        "        #     best_val_f1 = metrics[\"val/f1\"]\n",
        "        #     torch.save(model.state_dict(), os.path.join(checkpoint_dir, \"best_model.pt\"))\n",
        "        #     wandb.save(os.path.join(checkpoint_dir, \"best_model.pt\"))\n",
        "        # 💾 Save checkpoint for this epoch\n",
        "\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scaler_state_dict': scaler.state_dict(),\n",
        "            'best_f1': best_val_f1\n",
        "        }\n",
        "        torch.save(checkpoint, os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1}.pt\"))\n",
        "        print(f\"💾 Saved checkpoint for epoch {epoch+1}\")\n",
        "\n",
        "    wandb.finish()\n"
      ],
      "metadata": {
        "id": "qtQdBDsJAOfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(train_loader, val_loader, resume=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kNaLHKFSL36_",
        "outputId": "75638ae3-1a3c-43a1-f250-48d4f37e6ad8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-8e1ef5fb326c>:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Manually resumed from epoch 20 (loaded checkpoint_epoch_20.pt)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 21/24 [Train]:   0%|          | 0/5127 [00:00<?, ?it/s]<ipython-input-14-8e1ef5fb326c>:68: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 21/24 [Train]: 100%|██████████| 5127/5127 [31:32<00:00,  2.71it/s]\n",
            "Epoch 21/24 [Val]: 100%|██████████| 570/570 [04:29<00:00,  2.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Saved checkpoint for epoch 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 22/24 [Train]:   0%|          | 0/5127 [00:00<?, ?it/s]<ipython-input-14-8e1ef5fb326c>:68: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 22/24 [Train]: 100%|██████████| 5127/5127 [31:24<00:00,  2.72it/s]\n",
            "Epoch 22/24 [Val]: 100%|██████████| 570/570 [04:28<00:00,  2.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Saved checkpoint for epoch 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 23/24 [Train]:   0%|          | 0/5127 [00:00<?, ?it/s]<ipython-input-14-8e1ef5fb326c>:68: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 23/24 [Train]: 100%|██████████| 5127/5127 [31:26<00:00,  2.72it/s]\n",
            "Epoch 23/24 [Val]: 100%|██████████| 570/570 [04:29<00:00,  2.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Saved checkpoint for epoch 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 24/24 [Train]:   0%|          | 0/5127 [00:00<?, ?it/s]<ipython-input-14-8e1ef5fb326c>:68: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 24/24 [Train]: 100%|██████████| 5127/5127 [31:22<00:00,  2.72it/s]\n",
            "Epoch 24/24 [Val]: 100%|██████████| 570/570 [04:29<00:00,  2.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "💾 Saved checkpoint for epoch 24\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▆█</td></tr><tr><td>train/accuracy</td><td>▁▆██</td></tr><tr><td>train/f1</td><td>▁▆██</td></tr><tr><td>train/loss</td><td>█▁▁▂</td></tr><tr><td>train/precision</td><td>▁▃▄█</td></tr><tr><td>train/recall</td><td>▁▇█▃</td></tr><tr><td>val/accuracy</td><td>▅█▅▁</td></tr><tr><td>val/f1</td><td>▂█▅▁</td></tr><tr><td>val/loss</td><td>█▁▁▂</td></tr><tr><td>val/precision</td><td>█▄▃▁</td></tr><tr><td>val/recall</td><td>▁▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>24</td></tr><tr><td>train/accuracy</td><td>0.99921</td></tr><tr><td>train/f1</td><td>0.99902</td></tr><tr><td>train/loss</td><td>1e-05</td></tr><tr><td>train/precision</td><td>0.99912</td></tr><tr><td>train/recall</td><td>0.99892</td></tr><tr><td>val/accuracy</td><td>0.97449</td></tr><tr><td>val/f1</td><td>0.96817</td></tr><tr><td>val/loss</td><td>1e-05</td></tr><tr><td>val/precision</td><td>0.96731</td></tr><tr><td>val/recall</td><td>0.96903</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">epoch_20-24_new</strong> at: <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/o6lkyvij' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3/runs/o6lkyvij</a><br> View project at: <a href='https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3' target=\"_blank\">https://wandb.ai/muhib-57838-iqra-university/distilbert_cnn_v3</a><br>Synced 5 W&B file(s), 8 media file(s), 16 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250419_112953-o6lkyvij/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/trained_model_v3/checkpoint_epoch_4.pt"
      ],
      "metadata": {
        "id": "oe5ZuChvtvbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Validation Loss Calculator\n",
        "def calculate_validation_loss(checkpoint_path, val_loader, device, criterion):\n",
        "    \"\"\"Calculate and print only validation loss for a checkpoint\"\"\"\n",
        "    # Initialize model\n",
        "    model = DistilBERT_CNN().to(device)\n",
        "\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    # Calculate loss\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Calculating Loss\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].float().to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask).squeeze()\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    print(f\"\\n🔍 Validation Loss for {checkpoint_path}:\")\n",
        "    print(f\"- Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# Cell 11: Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize criterion with same parameters as training\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([config.pos_weight]).to(config.device))\n",
        "\n",
        "    # Checkpoint to evaluate\n",
        "    checkpoint_path = \"/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/trained_model_v3/checkpoint_epoch_7.pt\"\n",
        "\n",
        "    # Calculate and print only loss\n",
        "    calculate_validation_loss(\n",
        "        checkpoint_path=checkpoint_path,\n",
        "        val_loader=val_loader,\n",
        "        device=config.device,\n",
        "        criterion=criterion\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw_cRMpGx1rg",
        "outputId": "cfe6dd4e-92f3-4317-b5e1-af40eb9a19d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating Loss: 100%|██████████| 570/570 [04:22<00:00,  2.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Validation Loss for /content/drive/MyDrive/FYP Suicide Detection/DistilBERT/DistilBERTCNN/trained_model_v3/checkpoint_epoch_7.pt:\n",
            "- Loss: 0.1909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import wandb\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "LvPfjHf6ocew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Improved version of code !!!!!!!!!!!!!!!!!\n",
        "# Cell 10: Validation Loss Calculator (Improved)\n",
        "\n",
        "def validate_model(checkpoint_path, val_loader, device, criterion):\n",
        "    \"\"\"Validate a checkpoint with full metrics including loss\"\"\"\n",
        "    # Initialize model\n",
        "    model = DistilBERT_CNN().to(device)\n",
        "\n",
        "    # Load checkpoint\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        raise FileNotFoundError(f\"Checkpoint {checkpoint_path} not found!\")\n",
        "\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize metrics\n",
        "    total_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].float().to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask).squeeze()\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Get predictions\n",
        "            preds = (torch.sigmoid(outputs) > 0.5).cpu().float()\n",
        "            all_preds.extend(preds.numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    avg_loss = total_loss / len(val_loader)\n",
        "    accuracy = (np.array(all_labels) == np.array(all_preds)).mean()\n",
        "    precision = precision_score(all_labels, all_preds, zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # Print comprehensive results\n",
        "    print(\"\\n📊 Complete Validation Metrics:\")\n",
        "    print(f\"- Loss:      {avg_loss:.4f}\")\n",
        "    print(f\"- Accuracy:  {accuracy:.4f}\")\n",
        "    print(f\"- Precision: {precision:.4f}\")\n",
        "    print(f\"- Recall:    {recall:.4f}\")\n",
        "    print(f\"- F1 Score:  {f1:.4f}\")\n",
        "    print(\"\\n🔍 Confusion Matrix:\")\n",
        "    print(f\"               Predicted 0 (Non-Suicidal)  Predicted 1 (Suicidal)\")\n",
        "    print(f\"Actual 0 (Non-Suicidal) {cm[0,0]:>18} {cm[0,1]:>18}\")\n",
        "    print(f\"Actual 1 (Suicidal)     {cm[1,0]:>18} {cm[1,1]:>18}\")\n",
        "\n",
        "# Cell 11: Example Usage with Full Metrics\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize criterion with same parameters as training\n",
        "    criterion = nn.BCEWithLogitsLoss(\n",
        "        pos_weight=torch.tensor([config.pos_weight]).to(config.device)\n",
        "    )\n",
        "\n",
        "    # # Validate best model\n",
        "    # best_model_path = f\"{config.save_dir}/best_model.pt\"\n",
        "    # validate_model(best_model_path, val_loader, config.device, criterion)\n",
        "    model = DistilBERT_CNN().to(config.device)\n",
        "\n",
        "    # Validate specific checkpoint\n",
        "    epoch_checkpoint = f\"{config.save_dir}/checkpoint_epoch_24.pt\"\n",
        "    validate_model(epoch_checkpoint, val_loader, config.device, criterion)"
      ],
      "metadata": {
        "id": "bkEiI2bezEwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f32b087c-c77b-4d0b-c5b2-89f886e08043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 570/570 [04:29<00:00,  2.12it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Complete Validation Metrics:\n",
            "- Loss:      0.2488\n",
            "- Accuracy:  0.9745\n",
            "- Precision: 0.9673\n",
            "- Recall:    0.9690\n",
            "- F1 Score:  0.9682\n",
            "\n",
            "🔍 Confusion Matrix:\n",
            "               Predicted 0 (Non-Suicidal)  Predicted 1 (Suicidal)\n",
            "Actual 0 (Non-Suicidal)              10692                239\n",
            "Actual 1 (Suicidal)                    226               7071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Model Testing with Confidence Scores\n",
        "def test_sample_statements(model, tokenizer, device, statements, threshold=0.5):\n",
        "    \"\"\"Test the model on custom statements with confidence metrics\"\"\"\n",
        "    # Prepare model for inference\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize inputs\n",
        "    encodings = tokenizer(statements,\n",
        "                         padding=True,\n",
        "                         truncation=True,\n",
        "                         max_length=256,\n",
        "                         return_tensors=\"pt\")\n",
        "\n",
        "    # Move to device\n",
        "    input_ids = encodings['input_ids'].to(device)\n",
        "    attention_mask = encodings['attention_mask'].to(device)\n",
        "\n",
        "    # Get predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask).squeeze()\n",
        "        probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
        "\n",
        "    # Generate predictions and confidence metrics\n",
        "    results = []\n",
        "    for text, prob in zip(statements, probabilities):\n",
        "        prediction = 1 if prob >= threshold else 0\n",
        "        confidence = prob if prediction == 1 else 1 - prob\n",
        "        class_0_prob = 1 - prob\n",
        "        class_1_prob = prob\n",
        "\n",
        "        results.append({\n",
        "            \"text\": text,\n",
        "            \"prediction\": \"Suicidal\" if prediction == 1 else \"Non-Suicidal\",\n",
        "            \"confidence\": f\"{confidence:.1%}\",\n",
        "            \"probability_distribution\": {\n",
        "                \"Non-Suicidal\": f\"{class_0_prob:.3f}\",\n",
        "                \"Suicidal\": f\"{class_1_prob:.3f}\"\n",
        "            },\n",
        "            \"threshold_used\": threshold,\n",
        "            \"raw_output\": f\"{prob:.4f}\"\n",
        "        })\n",
        "\n",
        "    # Print formatted results\n",
        "    print(\"\\n🔍 Model Predictions with Confidence Scores:\")\n",
        "    for idx, result in enumerate(results, 1):\n",
        "        print(f\"\\n📄 Sample {idx}:\")\n",
        "        print(f\"- Text: {result['text']}\")\n",
        "        print(f\"- Prediction: {result['prediction']} (Confidence: {result['confidence']})\")\n",
        "        print(\"- Class Probabilities:\")\n",
        "        print(f\"  Non-Suicidal: {result['probability_distribution']['Non-Suicidal']}\")\n",
        "        print(f\"  Suicidal:     {result['probability_distribution']['Suicidal']}\")\n",
        "        print(f\"- Raw Output: {result['raw_output']} (Threshold: {result['threshold_used']})\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Cell 13: Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load components\n",
        "    model = DistilBERT_CNN().to(config.device)\n",
        "    checkpoint = torch.load(\n",
        "        f\"{config.save_dir}/checkpoint_epoch_24.pt\",\n",
        "        map_location=config.device\n",
        "    )\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])  # Key fix here\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained(config.model_checkpoint)\n",
        "\n",
        "    # Test samples\n",
        "    test_samples = [\n",
        "        \"I feel hopeless and want to end it all.\",\n",
        "        \"Today was the best day of my life!\",\n",
        "        \"Sometimes I wonder if anyone would care if I disappeared.\",\n",
        "        \"Just finished a great workout, feeling amazing!\",\n",
        "        \"The pain is too much to bear anymore.\"\n",
        "    ]\n",
        "\n",
        "    # Get predictions\n",
        "    predictions = test_sample_statements(model, tokenizer, config.device, test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZnnlTf24tjI",
        "outputId": "da2e44f0-f513-44c8-ac80-ddf96f14476e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Model Predictions with Confidence Scores:\n",
            "\n",
            "📄 Sample 1:\n",
            "- Text: I feel hopeless and want to end it all.\n",
            "- Prediction: Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.000\n",
            "  Suicidal:     1.000\n",
            "- Raw Output: 1.0000 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 2:\n",
            "- Text: Today was the best day of my life!\n",
            "- Prediction: Non-Suicidal (Confidence: 87.1%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.871\n",
            "  Suicidal:     0.129\n",
            "- Raw Output: 0.1285 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 3:\n",
            "- Text: Sometimes I wonder if anyone would care if I disappeared.\n",
            "- Prediction: Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.000\n",
            "  Suicidal:     1.000\n",
            "- Raw Output: 1.0000 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 4:\n",
            "- Text: Just finished a great workout, feeling amazing!\n",
            "- Prediction: Non-Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 1.000\n",
            "  Suicidal:     0.000\n",
            "- Raw Output: 0.0000 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 5:\n",
            "- Text: The pain is too much to bear anymore.\n",
            "- Prediction: Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.000\n",
            "  Suicidal:     1.000\n",
            "- Raw Output: 1.0000 (Threshold: 0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test samples\n",
        "test_samples = [\n",
        "  \"I feel hopeless and want to end it all.\",\n",
        "  \"Today was the best day of my life!\",\n",
        "  \"Sometimes I wonder if anyone would care if I disappeared.\",\n",
        "  \"Just finished a great workout, feeling amazing!\",\n",
        "  \"The pain is too much to bear anymore.\",\n",
        "  \"after one year of collecting these pieces of art, i present to you my collection.\",\n",
        "  \"i am spenttldr i have a hard life better than many, worse than other and it does not seem to get better. i am out of hope and am really close to giving up. to me, my life has always been shit. my dad ditched the family when i was five. my mom dated a string of abusive boyfriends one of them analy and orally raped me when i was 8, then threatened to have his friends rape and murder my entire family while i watched if i told anyone then she quickly graduated from alcoholism to meth addiction. we were evicted from almost every place we lived in, then my brother and i were taken in by a family we knew from church for about a year until they gave up on us because my mom, who at this point had ditched us to live in vegas with her methead boyfriend, refused to sign over custody of us to them. despite all this, i grew up with hope that somehow i could make my life better. i did terrible in school with a gpa of maybe 1.2 because i missed so many days, never did my homework, and just fucking hated life because i was always hungry, did not fit in with anyone, and was told all my life how ugly and fat i was because everyone else in my family was rail thin and short while i was tall and built like a linebacker. after highschool, i joined the military because it was the only way i could see getting out of poverty. my recruiter was the first person to pretend to believe in me and broke regulation to pay for my adult education classes so i could actually get a high school diploma to join it was 1999 at the time. i actually enjoyed the military and did well. it is wild what 3 meals a day and some actual structure will do for your life. i graduated in the top 10 and went to my first duty assignment overseas. we were at peace then, and things were going really well. i started taking college courses and met the love of my life during carnevale. then 911 happened. i deployed first to iraq in 2003 and saw a lot of shit. i was in a near ambush which wounded many of my pals and killed my best friend at the time.\",\n",
        "  \"sometimes I wish I had to kill someone using knife.\"\n",
        "\n",
        "]\n",
        "\n",
        "# Get predictions\n",
        "predictions = test_sample_statements(model, tokenizer, config.device, test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGJK09_j8ooI",
        "outputId": "d514d80d-a8a9-4075-e816-97be3f3a5767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Model Predictions with Confidence Scores:\n",
            "\n",
            "📄 Sample 1:\n",
            "- Text: I feel hopeless and want to end it all.\n",
            "- Prediction: Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.000\n",
            "  Suicidal:     1.000\n",
            "- Raw Output: 1.0000 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 2:\n",
            "- Text: Today was the best day of my life!\n",
            "- Prediction: Non-Suicidal (Confidence: 87.1%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.871\n",
            "  Suicidal:     0.129\n",
            "- Raw Output: 0.1287 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 3:\n",
            "- Text: Sometimes I wonder if anyone would care if I disappeared.\n",
            "- Prediction: Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.000\n",
            "  Suicidal:     1.000\n",
            "- Raw Output: 1.0000 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 4:\n",
            "- Text: Just finished a great workout, feeling amazing!\n",
            "- Prediction: Non-Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 1.000\n",
            "  Suicidal:     0.000\n",
            "- Raw Output: 0.0000 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 5:\n",
            "- Text: The pain is too much to bear anymore.\n",
            "- Prediction: Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.000\n",
            "  Suicidal:     1.000\n",
            "- Raw Output: 1.0000 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 6:\n",
            "- Text: after one year of collecting these pieces of art, i present to you my collection.\n",
            "- Prediction: Non-Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 1.000\n",
            "  Suicidal:     0.000\n",
            "- Raw Output: 0.0000 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 7:\n",
            "- Text: i am spenttldr i have a hard life better than many, worse than other and it does not seem to get better. i am out of hope and am really close to giving up. to me, my life has always been shit. my dad ditched the family when i was five. my mom dated a string of abusive boyfriends one of them analy and orally raped me when i was 8, then threatened to have his friends rape and murder my entire family while i watched if i told anyone then she quickly graduated from alcoholism to meth addiction. we were evicted from almost every place we lived in, then my brother and i were taken in by a family we knew from church for about a year until they gave up on us because my mom, who at this point had ditched us to live in vegas with her methead boyfriend, refused to sign over custody of us to them. despite all this, i grew up with hope that somehow i could make my life better. i did terrible in school with a gpa of maybe 1.2 because i missed so many days, never did my homework, and just fucking hated life because i was always hungry, did not fit in with anyone, and was told all my life how ugly and fat i was because everyone else in my family was rail thin and short while i was tall and built like a linebacker. after highschool, i joined the military because it was the only way i could see getting out of poverty. my recruiter was the first person to pretend to believe in me and broke regulation to pay for my adult education classes so i could actually get a high school diploma to join it was 1999 at the time. i actually enjoyed the military and did well. it is wild what 3 meals a day and some actual structure will do for your life. i graduated in the top 10 and went to my first duty assignment overseas. we were at peace then, and things were going really well. i started taking college courses and met the love of my life during carnevale. then 911 happened. i deployed first to iraq in 2003 and saw a lot of shit. i was in a near ambush which wounded many of my pals and killed my best friend at the time.\n",
            "- Prediction: Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.000\n",
            "  Suicidal:     1.000\n",
            "- Raw Output: 1.0000 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 8:\n",
            "- Text: sometimes I wish I had to kill someone using knife.\n",
            "- Prediction: Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.000\n",
            "  Suicidal:     1.000\n",
            "- Raw Output: 1.0000 (Threshold: 0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: Model Testing with Confidence Scores\n",
        "def test_sample_statements(model, tokenizer, device, statements, threshold=0.5):\n",
        "    \"\"\"Test the model on custom statements with confidence metrics\"\"\"\n",
        "    # Prepare model for inference\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize inputs\n",
        "    encodings = tokenizer(statements,\n",
        "                         padding=True,\n",
        "                         truncation=True,\n",
        "                         max_length=256,\n",
        "                         return_tensors=\"pt\")\n",
        "\n",
        "    # Move to device\n",
        "    input_ids = encodings['input_ids'].to(device)\n",
        "    attention_mask = encodings['attention_mask'].to(device)\n",
        "\n",
        "    # Get predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask).squeeze()\n",
        "        probabilities = torch.sigmoid(outputs).cpu().numpy()\n",
        "\n",
        "    # Generate predictions and confidence metrics\n",
        "    results = []\n",
        "    for text, prob in zip(statements, probabilities):\n",
        "        prediction = 1 if prob >= threshold else 0\n",
        "        confidence = prob if prediction == 1 else 1 - prob\n",
        "        class_0_prob = 1 - prob\n",
        "        class_1_prob = prob\n",
        "\n",
        "        results.append({\n",
        "            \"text\": text,\n",
        "            \"prediction\": \"Suicidal\" if prediction == 1 else \"Non-Suicidal\",\n",
        "            \"confidence\": f\"{confidence:.1%}\",\n",
        "            \"probability_distribution\": {\n",
        "                \"Non-Suicidal\": f\"{class_0_prob:.3f}\",\n",
        "                \"Suicidal\": f\"{class_1_prob:.3f}\"\n",
        "            },\n",
        "            \"threshold_used\": threshold,\n",
        "            \"raw_output\": f\"{prob:.4f}\"\n",
        "        })\n",
        "\n",
        "    # Print formatted results\n",
        "    print(\"\\n🔍 Model Predictions with Confidence Scores:\")\n",
        "    for idx, result in enumerate(results, 1):\n",
        "        print(f\"\\n📄 Sample {idx}:\")\n",
        "        print(f\"- Text: {result['text']}\")\n",
        "        print(f\"- Prediction: {result['prediction']} (Confidence: {result['confidence']})\")\n",
        "        print(\"- Class Probabilities:\")\n",
        "        print(f\"  Non-Suicidal: {result['probability_distribution']['Non-Suicidal']}\")\n",
        "        print(f\"  Suicidal:     {result['probability_distribution']['Suicidal']}\")\n",
        "        print(f\"- Raw Output: {result['raw_output']} (Threshold: {result['threshold_used']})\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Cell 13: Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Load components\n",
        "    model = DistilBERT_CNN().to(config.device)\n",
        "    checkpoint = torch.load(\n",
        "        f\"{config.save_dir}/checkpoint_epoch_24.pt\",\n",
        "        map_location=config.device\n",
        "    )\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])  # Key fix here\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained(config.model_checkpoint)\n",
        "\n",
        "    # Test samples\n",
        "    test_samples = [\n",
        "        \"I feel hopeless and want to end it all.\",\n",
        "        \"Today was the best day of my life!\",\n",
        "        \"Sometimes I wonder if anyone would care if I disappeared.\",\n",
        "        \"Just finished a great workout, feeling amazing!\",\n",
        "        \"The pain is too much to bear anymore.\"\n",
        "    ]\n",
        "\n",
        "    # Get predictions\n",
        "    predictions = test_sample_statements(model, tokenizer, config.device, test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voIMsvtGIYw5",
        "outputId": "e20a7ae6-3c3f-4a87-e3a1-a559c2e6bca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Model Predictions with Confidence Scores:\n",
            "\n",
            "📄 Sample 1:\n",
            "- Text: I feel hopeless and want to end it all.\n",
            "- Prediction: Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.000\n",
            "  Suicidal:     1.000\n",
            "- Raw Output: 1.0000 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 2:\n",
            "- Text: Today was the best day of my life!\n",
            "- Prediction: Non-Suicidal (Confidence: 87.1%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.871\n",
            "  Suicidal:     0.129\n",
            "- Raw Output: 0.1285 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 3:\n",
            "- Text: Sometimes I wonder if anyone would care if I disappeared.\n",
            "- Prediction: Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.000\n",
            "  Suicidal:     1.000\n",
            "- Raw Output: 1.0000 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 4:\n",
            "- Text: Just finished a great workout, feeling amazing!\n",
            "- Prediction: Non-Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 1.000\n",
            "  Suicidal:     0.000\n",
            "- Raw Output: 0.0000 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 5:\n",
            "- Text: The pain is too much to bear anymore.\n",
            "- Prediction: Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.000\n",
            "  Suicidal:     1.000\n",
            "- Raw Output: 1.0000 (Threshold: 0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test samples\n",
        "test_samples = [\n",
        "    \"I woke up this morning and started my day like usual—brushed my teeth, made a cup of coffee, sat by the window watching the street fill up with life, people hurrying to work, kids with backpacks rushing to catch the school bus, all of it so routine and uneventful that I didn’t even notice the time pass. It’s one of those days where nothing feels significant, nothing feels wrong either, but nothing excites me either. It’s just a day like any other, and that’s okay. Sometimes normalcy is a relief. Not everything has to be dramatic to be real.\",\n",
        "    \"Today was one of those rare days where everything just clicked—I finished my work early, caught up with an old friend over lunch, and took a long walk as the sun was setting, painting the sky in orange and purple hues. The cool breeze, the laughter, the tiny surprises throughout the day reminded me that joy doesn’t always come in big moments. It often sneaks in through quiet contentment, through shared smiles and peace in your chest.\",\n",
        "    \"Lately I’ve been feeling this heaviness I can’t quite explain. I get up, eat, work, sleep—but it all feels so empty. I don’t cry, I don’t scream, but there’s this dull ache under the surface, like I’m carrying a weight I can’t put down. I don’t want to alarm anyone, because I know it’s temporary. I’ve been here before and made it out, but this time it’s lonelier. I’m not thinking about ending things—I’m just tired. Tired of pretending I’m okay when I’m not, tired of smiling just so people don’t ask what’s wrong. I just want to feel like myself again.\",\n",
        "    \"There’s a part of me that wants to scream, but the other part stays silent because it’s safer that way. I walk through life wearing a mask, laughing at jokes that don’t land, pretending the hollow space inside me isn’t expanding by the day. No one notices the subtle shifts, the way I disappear even when I’m present. I think about what it would feel like to not feel anything at all. I’m not saying I want to die. I just want the pain to stop, to wake up one day and not dread the hours ahead. Is that too much to ask?\",\n",
        "    \"Every night I lie awake thinking about how much easier everything would be if I just closed my eyes and never had to wake up again. I’ve tried reaching out, I’ve tried therapy, medication, prayer, everything people tell you to try when you’re drowning—but nothing changes. It’s like the sadness has wrapped itself around my bones. I don’t want to keep pretending I’m okay when I’m not. I don’t want to keep being strong when every cell in my body begs me to let go. Maybe people will be sad for a while, but eventually they’ll move on. They always do.\"\n",
        "\n",
        "]\n",
        "\n",
        "    # Get predictions\n",
        "predictions = test_sample_statements(model, tokenizer, config.device, test_samples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdgjklZZs8RM",
        "outputId": "6a7b0bd4-0cc8-41df-b384-47e8d41f1415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Model Predictions with Confidence Scores:\n",
            "\n",
            "📄 Sample 1:\n",
            "- Text: I woke up this morning and started my day like usual—brushed my teeth, made a cup of coffee, sat by the window watching the street fill up with life, people hurrying to work, kids with backpacks rushing to catch the school bus, all of it so routine and uneventful that I didn’t even notice the time pass. It’s one of those days where nothing feels significant, nothing feels wrong either, but nothing excites me either. It’s just a day like any other, and that’s okay. Sometimes normalcy is a relief. Not everything has to be dramatic to be real.\n",
            "- Prediction: Non-Suicidal (Confidence: 99.9%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.999\n",
            "  Suicidal:     0.001\n",
            "- Raw Output: 0.0007 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 2:\n",
            "- Text: Today was one of those rare days where everything just clicked—I finished my work early, caught up with an old friend over lunch, and took a long walk as the sun was setting, painting the sky in orange and purple hues. The cool breeze, the laughter, the tiny surprises throughout the day reminded me that joy doesn’t always come in big moments. It often sneaks in through quiet contentment, through shared smiles and peace in your chest.\n",
            "- Prediction: Non-Suicidal (Confidence: 99.3%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.993\n",
            "  Suicidal:     0.007\n",
            "- Raw Output: 0.0068 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 3:\n",
            "- Text: Lately I’ve been feeling this heaviness I can’t quite explain. I get up, eat, work, sleep—but it all feels so empty. I don’t cry, I don’t scream, but there’s this dull ache under the surface, like I’m carrying a weight I can’t put down. I don’t want to alarm anyone, because I know it’s temporary. I’ve been here before and made it out, but this time it’s lonelier. I’m not thinking about ending things—I’m just tired. Tired of pretending I’m okay when I’m not, tired of smiling just so people don’t ask what’s wrong. I just want to feel like myself again.\n",
            "- Prediction: Non-Suicidal (Confidence: 96.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.960\n",
            "  Suicidal:     0.040\n",
            "- Raw Output: 0.0395 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 4:\n",
            "- Text: There’s a part of me that wants to scream, but the other part stays silent because it’s safer that way. I walk through life wearing a mask, laughing at jokes that don’t land, pretending the hollow space inside me isn’t expanding by the day. No one notices the subtle shifts, the way I disappear even when I’m present. I think about what it would feel like to not feel anything at all. I’m not saying I want to die. I just want the pain to stop, to wake up one day and not dread the hours ahead. Is that too much to ask?\n",
            "- Prediction: Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.000\n",
            "  Suicidal:     1.000\n",
            "- Raw Output: 1.0000 (Threshold: 0.5)\n",
            "\n",
            "📄 Sample 5:\n",
            "- Text: Every night I lie awake thinking about how much easier everything would be if I just closed my eyes and never had to wake up again. I’ve tried reaching out, I’ve tried therapy, medication, prayer, everything people tell you to try when you’re drowning—but nothing changes. It’s like the sadness has wrapped itself around my bones. I don’t want to keep pretending I’m okay when I’m not. I don’t want to keep being strong when every cell in my body begs me to let go. Maybe people will be sad for a while, but eventually they’ll move on. They always do.\n",
            "- Prediction: Suicidal (Confidence: 100.0%)\n",
            "- Class Probabilities:\n",
            "  Non-Suicidal: 0.000\n",
            "  Suicidal:     1.000\n",
            "- Raw Output: 1.0000 (Threshold: 0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing on another dataset\n",
        "\n",
        "# Cell 12: Twitter Dataset Evaluator\n",
        "def evaluate_twitter_dataset(checkpoint_path, tweet_csv_path, device):\n",
        "    \"\"\"\n",
        "    Evaluate model on Twitter dataset with comprehensive metrics\n",
        "    Args:\n",
        "        checkpoint_path: Path to model checkpoint\n",
        "        tweet_csv_path: Path to CSV with 'text' and 'label' columns\n",
        "        device: torch.device ('cuda' or 'cpu')\n",
        "    Returns:\n",
        "        Dictionary containing all evaluation metrics\n",
        "    \"\"\"\n",
        "    # 1. Load Model\n",
        "    model = DistilBERT_CNN().to(device)\n",
        "    model.load_state_dict(torch.load(checkpoint_path, map_location=device)['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    # 2. Prepare Dataset (Matching Training Preprocessing)\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained(config.model_checkpoint)\n",
        "\n",
        "    class TweetDataset(Dataset):\n",
        "        def __init__(self, texts, labels):\n",
        "            self.encodings = tokenizer(\n",
        "                texts,\n",
        "                padding=True,\n",
        "                truncation=True,\n",
        "                max_length=256,\n",
        "                return_tensors=\"pt\"\n",
        "            )\n",
        "            self.labels = labels\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            return {\n",
        "                'input_ids': self.encodings['input_ids'][idx],\n",
        "                'attention_mask': self.encodings['attention_mask'][idx],\n",
        "                'labels': torch.tensor(self.labels[idx])\n",
        "            }\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.labels)\n",
        "\n",
        "    # Load and prepare data\n",
        "    tweet_csv_path = \"/content/drive/MyDrive/FYP Suicide Detection/DistilBERT/datasets/twitter_labelled_v1.csv\"\n",
        "    df = pd.read_csv(tweet_csv_path)\n",
        "    dataset = TweetDataset(df['text'].tolist(), df['label'].values)\n",
        "    loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # 3. Evaluation Metrics\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([config.pos_weight]).to(device))\n",
        "    results = {\n",
        "        'pred_probs': [],\n",
        "        'pred_labels': [],\n",
        "        'true_labels': []\n",
        "    }\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc=\"Evaluating Tweets\"):\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
        "            labels = batch['labels'].float().to(device)\n",
        "\n",
        "            outputs = model(**inputs).squeeze()\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            probs = torch.sigmoid(outputs).cpu().numpy()\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "\n",
        "            results['pred_probs'].extend(probs)\n",
        "            results['pred_labels'].extend(preds)\n",
        "            results['true_labels'].extend(labels.cpu().numpy())\n",
        "\n",
        "    # 4. Calculate Metrics\n",
        "    metrics = {\n",
        "        'loss': total_loss / len(loader),\n",
        "        'accuracy': accuracy_score(results['true_labels'], results['pred_labels']),\n",
        "        'precision': precision_score(results['true_labels'], results['pred_labels'], zero_division=0),\n",
        "        'recall': recall_score(results['true_labels'], results['pred_labels'], zero_division=0),\n",
        "        'f1': f1_score(results['true_labels'], results['pred_labels'], zero_division=0),\n",
        "        'confusion_matrix': confusion_matrix(results['true_labels'], results['pred_labels']),\n",
        "        'classification_report': classification_report(\n",
        "            results['true_labels'],\n",
        "            results['pred_labels'],\n",
        "            target_names=['Non-Suicidal', 'Suicidal'])\n",
        "    }\n",
        "\n",
        "    # 5. Visualization-Ready Outputs\n",
        "    print(\"\\n🔥 Twitter Dataset Evaluation 🔥\")\n",
        "    print(f\"Model: {os.path.basename(checkpoint_path)}\")\n",
        "    print(f\"Samples: {len(results['true_labels'])}\")\n",
        "    print(f\"\\n📊 Key Metrics:\")\n",
        "    print(f\"- Loss: {metrics['loss']:.4f}\")\n",
        "    print(f\"- Accuracy: {metrics['accuracy']:.4f}\")\n",
        "    print(f\"- Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"- Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"- F1: {metrics['f1']:.4f}\")\n",
        "\n",
        "    print(\"\\n🧮 Confusion Matrix:\")\n",
        "    print(pd.DataFrame(\n",
        "        metrics['confusion_matrix'],\n",
        "        index=['Actual Non-Suicidal', 'Actual Suicidal'],\n",
        "        columns=['Predicted Non-Suicidal', 'Predicted Suicidal']\n",
        "    ))\n",
        "\n",
        "    print(\"\\n📝 Classification Report:\")\n",
        "    print(metrics['classification_report'])\n",
        "\n",
        "    return metrics, results\n",
        "\n",
        "# Cell 13: Execution Example\n",
        "if __name__ == \"__main__\":\n",
        "    # Configuration\n",
        "    config = Config()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Paths (update these)\n",
        "    checkpoint_path = f\"{config.save_dir}/checkpoint_epoch_24.pt\"\n",
        "    tweet_csv_path = \"path/to/twitter_dataset.csv\"\n",
        "\n",
        "    # Run evaluation\n",
        "    metrics, detailed_results = evaluate_twitter_dataset(\n",
        "        checkpoint_path=checkpoint_path,\n",
        "        tweet_csv_path=tweet_csv_path,\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    # Optional: Save results\n",
        "    pd.DataFrame({\n",
        "        'text': pd.read_csv(tweet_csv_path)['text'],\n",
        "        'true_label': detailed_results['true_labels'],\n",
        "        'pred_label': detailed_results['pred_labels'],\n",
        "        'pred_prob': detailed_results['pred_probs']\n",
        "    }).to_csv(\"twitter_predictions.csv\", index=False)"
      ],
      "metadata": {
        "id": "eI_AVh1eKX19"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}